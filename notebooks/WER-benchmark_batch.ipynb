{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Türkçe karakterler için özel büyütme ve küçültme eşlemeleri\n",
    "turkish_upper_chars = {\"ı\": \"I\", \"i\": \"İ\", \"ş\": \"Ş\", \"ğ\": \"Ğ\", \"ü\": \"Ü\", \"ö\": \"Ö\", \"ç\": \"Ç\"}\n",
    "turkish_lower_chars = {v: k for k, v in turkish_upper_chars.items()}\n",
    "\n",
    "\n",
    "def turkish_upper(s):\n",
    "    return \"\".join(turkish_upper_chars.get(c, c.upper()) for c in s)\n",
    "\n",
    "\n",
    "def turkish_lower(s):\n",
    "    return \"\".join(turkish_lower_chars.get(c, c.lower()) for c in s)\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply normalization to text described in Moonshine: Speech Recognition for Live Transcription and Voice Commands\n",
    "    https://arxiv.org/html/2410.15608v2\n",
    "\n",
    "    Handle Turkish specific characters, use helper functions defined earlier.\n",
    "    \"\"\"\n",
    "\n",
    "    text = turkish_lower(text)\n",
    "    text = re.sub(r'[^a-zçğıöşü]', ' ', text).replace(\"  \", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "\n",
    "# import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from ytk.normalizer import normalize_dictation\n",
    "from evaluate import load\n",
    "\n",
    "from asrtk.utils.text import normalize_text\n",
    "\n",
    "print(normalize_text(\"Çok iyi ve nazik biriydi. Prusya’daki ilk karşılaşmamızda onu konuşturmayı başarmıştım. Bana o yaz North Cape’de bulunduğunu ve Nijni Novgorod panayırına gitmeyi çok istediğini anlatmıştı.,;)([-*])\"))\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "SAMPLE_RATE = 16000  # Sample rate in Hz\n",
    "NUM_SAMPLES_TO_TRIM = 0  # 4 * SAMPLE_RATE  # Number of samples in 4 seconds\n",
    "SYNT_LABELS = False\n",
    "device = \"cuda\"\n",
    "batch_size = 1  # reduce if low on GPU mem\n",
    "compute_type = \"int8\"  # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "# compute_type = \"float32\"\n",
    "\n",
    "asr_options = {\n",
    "    # \"temperatures\": 0.0,\n",
    "    # \"beam_size\": 1,\n",
    "    \"condition_on_previous_text\": False,\n",
    "    # \"initial_prompt\": \"\"\n",
    "    \"hotwords\": None,\n",
    "    \"multilingual\": False,\n",
    "}\n",
    "\n",
    "# model = whisperx.load_model(\"base\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  #\n",
    "model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-large-v3-turbo\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  #\n",
    "\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-15k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  #\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-e1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  #\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-large-v3-turbo-med-tr-30k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # Çok iyi. İlk finetune, frozen, drop active, bütün parametreler vardı. Bu ctranslatre2 tokenizer vs json dosyaların ıhatalı oluşturduğu için kötü sonuç veriyormuş meğer.\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-large-v3-turbo-med-tr-2-40k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # iyi, encoder frozen olmalı. İlki yarım kalınca ve inference ı hatalı yapınca buna geçmiştim. Kısaltmaları tam öğrenememiş. Yukarıdaki daha iyi.\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-khanacademy-large-v3-turbo-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # Başarılı, bazı terimler ve kısaltmaları bilmiyor.\n",
    "\n",
    "\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-base-med-tr-120k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # olacak gibi ama bazı terimlerde bariz hatalar yapıyor. Henüz görmemiş.\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-base-med-tr-2nd-30k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # olacak gibi, bazı terimleri öğrenmemiş. Henüz görmemiş.\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-tiny-med-tr-65k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # olmaya çalışıyor\n",
    "\n",
    "\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-tiny-dsntt1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # , asr_options=asr_options) kötü\n",
    "\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/base-dsntt1-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/small-dsntt1-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # iyi\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/medium-dsntt1-LoRA\", device, compute_type=compute_type, download_root=\"n:/whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/v2-dsntt1-LoRA-2-ck32000\", device, compute_type=compute_type, download_root=\"n:/whisperx_models\", language=\"tr\")  # , asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/small-re-dsn1-ck6k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\")  # , asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/large-v2-dsntt1-tr-ck71k\", device, compute_type=compute_type, download_root=\"n:/whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/large-v3-dsntt1-tr\", device, compute_type=compute_type, download_root=\"n:/whisperx_models\", language=\"tr\")  # , asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"small\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\")  # , asr_options=asr_options)\n",
    "\n",
    "# model.model.feature_extractor.mel_filters = model.model.feature_extractor.get_mel_filters(model.model.feature_extractor.sampling_rate, model.model.feature_extractor.n_fft, n_mels=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_files(dataset_dir, n=25, file_type=\"opus\"):\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    opus_files = list(dataset_dir.rglob(f'*.{file_type}'))\n",
    "    print(len(opus_files))\n",
    "    sorted_opus_files = sorted(opus_files, key=lambda x: x.stat().st_size, reverse=True)\n",
    "    top_n_files = sorted_opus_files[:n]\n",
    "    top_n_files_with_size = [(str(file), file.stat().st_size) for file in top_n_files]\n",
    "\n",
    "    for file, size in top_n_files_with_size:\n",
    "        print(f\"{file}: {size / 1024:.0f} KB\")\n",
    "    return top_n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_files(dataset_dir, n=25, file_type=\"opus\"):\n",
    "    seed=42\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    opus_files = list(dataset_dir.rglob(f'*.{file_type}'))\n",
    "    random.Random(seed).shuffle(opus_files)\n",
    "    top_n_files = opus_files[:n]\n",
    "    top_n_files_with_size = [(str(file), file.stat().st_size) for file in top_n_files]\n",
    "\n",
    "    for file, size in top_n_files_with_size:\n",
    "        print(f\"{file}: {size / 1024:.0f} KB\")\n",
    "    return top_n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(audio_path, normalize=True):\n",
    "    start = time.time()\n",
    "    audio = whisperx.load_audio(audio_path)\n",
    "\n",
    "    # if not SYNT_LABELS:\n",
    "    #     audio = audio[NUM_SAMPLES_TO_TRIM:]  # If not using synthetic labels, trim the first 4 seconds cause RL recordings have 4 seconds of garbage at the beginning.\n",
    "\n",
    "    num_samples = audio.shape[0]  # Get the number of samples from the shape\n",
    "    audio_length = round(num_samples / SAMPLE_RATE, 3)\n",
    "\n",
    "    result = model.transcribe(audio, batch_size=batch_size, print_progress=False, language=\"tr\")\n",
    "    transcription_time = round(time.time() - start, 2)\n",
    "    prediction = \"\"\n",
    "    for result in result[\"segments\"]:\n",
    "        prediction += result[\"text\"] + \" \"\n",
    "\n",
    "    prediction = normalize_dictation(prediction)\n",
    "\n",
    "    return prediction, transcription_time, audio_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ytk.normalizer import fill_dates\n",
    "# from ytk.utils import turkish_capitalize\n",
    "from webvtt import read as read_vtt\n",
    "\n",
    "SYNT_LABELS = False\n",
    "n = 5000\n",
    "\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\YENI_SPLIT_LQ_NOISY\"\n",
    "INPUT_DIR = r\"N:\\dataset_v3\\YENI_SPLIT\"\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\commonvoice_17_tr\\commonvoice_17_tr_fixed\\test\"\n",
    "\n",
    "file_list = get_random_files(INPUT_DIR, n, file_type=\"mp3\")\n",
    "print(len(file_list))\n",
    "\n",
    "total_wer = 0\n",
    "avg_wer = 0\n",
    "processed_files = 0\n",
    "label_pairs = []\n",
    "\n",
    "def get_text_from_file(file_path):\n",
    "    \"\"\"Extract text from either VTT or TXT file.\"\"\"\n",
    "    try:\n",
    "        # Check file extension\n",
    "        if file_path.suffix.lower() == '.vtt':\n",
    "            captions = read_vtt(str(file_path))\n",
    "            transcription = ' '.join(caption.text.replace('\\n', ' ') for caption in captions)\n",
    "        else:  # Assume txt file\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                transcription = f.read().replace('\\n', ' ')\n",
    "        \n",
    "        return transcription.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "for audio_path in file_list:\n",
    "    try:\n",
    "        # Try VTT first, then TXT\n",
    "        vtt_file = audio_path.with_suffix('.vtt')\n",
    "        txt_file = audio_path.with_suffix('.txt')\n",
    "        \n",
    "        if vtt_file.exists():\n",
    "            reference = get_text_from_file(vtt_file)\n",
    "            transcript_file = vtt_file\n",
    "        elif txt_file.exists():\n",
    "            reference = get_text_from_file(txt_file)\n",
    "            transcript_file = txt_file\n",
    "        else:\n",
    "            print(f\"No transcript file found for {audio_path}\")\n",
    "            continue\n",
    "            \n",
    "        if not reference or len(reference) < 5:\n",
    "            continue\n",
    "\n",
    "\n",
    "        prediction, transcription_time, audio_length = transcript(audio_path)\n",
    "        # prediction = prediction.replace(\" x \", \"x\")\n",
    "\n",
    "        if \"No active speech found in audio\" in prediction:\n",
    "            continue\n",
    "\n",
    "        rf, pre = reference, prediction\n",
    "\n",
    "        prediction = normalize_text(prediction)\n",
    "        reference = normalize_text(reference)\n",
    "\n",
    "        wer = wer_metric.compute(references=[reference], predictions=[prediction])\n",
    "        total_wer += wer\n",
    "        processed_files += 1\n",
    "        avg_wer = total_wer / processed_files\n",
    "\n",
    "        label_pairs.append((f\"{wer * 100:0.02f}\", rf, pre))\n",
    "\n",
    "        print(rf)\n",
    "        print(pre)\n",
    "        print(f\"{processed_files}/{len(file_list)} Avg WER: {avg_wer * 100:0.02f}%, WER: {wer * 100:0.02f}%, {transcript_file} - Duration: {audio_length} sec, Speed: {transcription_time / audio_length:0.02f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "\n",
    "with open(\"labels-base-new.tsv\", \"w\", encoding=\"utf-8\") as lf:\n",
    "    for wer, r, p in label_pairs:\n",
    "        lf.write(f\"{wer}\\t{r}\\t{p}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
