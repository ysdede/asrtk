{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "turkish_upper_chars = {\"ı\": \"I\", \"i\": \"İ\", \"ş\": \"Ş\", \"ğ\": \"Ğ\", \"ü\": \"Ü\", \"ö\": \"Ö\", \"ç\": \"Ç\"}\n",
    "\n",
    "turkish_hatted_chars = {\n",
    "    \"â\": \"a\",\n",
    "    \"Â\": \"A\",\n",
    "    \"î\": \"i\",\n",
    "    \"Î\": \"I\",\n",
    "    \"û\": \"u\",\n",
    "    \"Û\": \"U\",\n",
    "    \"ô\": \"o\",  # Bazı metinlerde karşılaşılabiliyor, standartta yer almamakla birlikte eklenmiştir.\n",
    "    \"Ô\": \"O\"\n",
    "}\n",
    "turkish_lower_chars = {v: k for k, v in turkish_upper_chars.items()}\n",
    "\n",
    "def replace_hatted_characters(s):\n",
    "    for k, v in turkish_hatted_chars.items():\n",
    "        s = s.replace(k, v)\n",
    "    return s\n",
    "\n",
    "def turkish_lower(s):\n",
    "    return \"\".join(turkish_lower_chars.get(c, c.lower()) for c in s)\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply normalization to text described in Moonshine: Speech Recognition for Live Transcription and Voice Commands\n",
    "    https://arxiv.org/html/2410.15608v2\n",
    "\n",
    "    Handle Turkish specific characters, use helper functions defined earlier.\n",
    "    \"\"\"\n",
    "    text = text.replace(\" '\", \"'\").replace(\"' \", \" \").replace(\"'\", \"\")\n",
    "    text = replace_hatted_characters(text)\n",
    "    text = turkish_lower(text)\n",
    "    text = re.sub(r'[^a-zçğıöşü]', ' ', text).replace(\"  \", \" \")\n",
    "    return text.strip()\n",
    "\n",
    "print(normalize_text(\"âîôû Çok iyi ve nazik biriydi. Prusya'daki ilk karşılaşmamızda onu konuşturmayı başarmıştım. Bana o yaz North Cape’de bulunduğunu ve Nijni Novgorod panayırına gitmeyi çok istediğini anlatmıştı.,;)([-*])\"))\n",
    "print(replace_hatted_characters(\"âîôû Çok iyi ve nazik biriydi. Prusya'daki ilk karşılaşmamızda onu konuşturmayı başarmıştım. Bana o yaz North Cape’de bulunduğunu ve Nijni Novgorod panayırına gitmeyi çok istediğini anlatmıştı.,;)([-*])\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import numpy as np\n",
    "# import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "SAMPLE_RATE = 16000  # Sample rate in Hz\n",
    "NUM_SAMPLES_TO_TRIM = 0  # 4 * SAMPLE_RATE  # Number of samples in 4 seconds\n",
    "SYNT_LABELS = False\n",
    "device = \"cuda\"\n",
    "batch_size = 1  # reduce if low on GPU mem\n",
    "compute_type = \"int8\"  # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "# compute_type = \"float32\"\n",
    "\n",
    "asr_options = {\n",
    "    # \"temperatures\": 0.0,\n",
    "    # \"beam_size\": 5,\n",
    "    \"condition_on_previous_text\": False,\n",
    "    # \"initial_prompt\": \"\"\n",
    "    \"hotwords\": None,\n",
    "    \"multilingual\": False,\n",
    "}\n",
    "\n",
    "# vad_options = {\"vad_onset\": 0.500, \"vad_offset\": 0.363}\n",
    "                                                                                                                                                                                                                #    cv 17 test   # tr tts       | dsn test\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-large-v3-turbo\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # 12.91   0.058   / 12    0.032 | 14.75  0.071 | 20\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   # 20.5           / 19.3  0.066 | 36.34  0.137 | 33   0.08\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   # 17.7    0.069  / 14.86 0.06  | 37.9   0.147 | 32.8 0.08 \n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-1.1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options) # 17      0.065  / 13.95 0.056 | 36  0.143\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-small-turkish-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # 13.6    0.054  / 8.48  0.048 | 22.6   0.094 | 28\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-small-turkish-1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # 15.05   0.061  / 8.65  0.026 | 24.7  0.099  | 27.5  0.063\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-tiny-turkish-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   # 25.8    0.096  / 20.5  0.065\n",
    "# model = whisperx.load_model(\"N:/models/faster/Systran/faster-whisper-base\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)     # 33      0.130   / 44  0.157\n",
    "# model = whisperx.load_model(\"N:/models/faster/Systran/faster-whisper-small\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)    # 21      0.084  | 29.25 0.295             | 27.6  0.106\n",
    "\n",
    "\n",
    "\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/base-dsntt1-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/small-dsntt1-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-small-turkish-0-med-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-1.1-med\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "\n",
    "\n",
    "# model = whisperx.load_model(\"Systran/faster-whisper-tiny\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)                      # \n",
    "\n",
    "\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-large-v3-turbo-med-tr-30k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # Çok iyi. İlk finetune, frozen, drop active, bütün parametreler vardı. Bu ctranslatre2 tokenizer vs json dosyaların ıhatalı oluşturduğu için kötü sonuç veriyormuş meğer.\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-large-v3-turbo-med-tr-2-40k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # iyi, encoder frozen olmalı. İlki yarım kalınca ve inference ı hatalı yapınca buna geçmiştim. Kısaltmaları tam öğrenememiş. Yukarıdaki daha iyi.\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-khanacademy-large-v3-turbo-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # Başarılı, bazı terimler ve kısaltmaları bilmiyor.\n",
    "\n",
    "\n",
    "# model = whisperx.load_model(r\"n:\\models\\faster\\emre\\whisper-medium-turkish-2\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "model = whisperx.load_model(\"deepdml/faster-whisper-large-v3-turbo-ct2\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_files(dataset_dir, n=25, file_type=\"opus\"):\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    opus_files = list(dataset_dir.rglob(f'*.{file_type}'))\n",
    "    print(len(opus_files))\n",
    "    sorted_opus_files = sorted(opus_files, key=lambda x: x.stat().st_size, reverse=True)\n",
    "    top_n_files = sorted_opus_files[:n]\n",
    "    top_n_files_with_size = [(str(file), file.stat().st_size) for file in top_n_files]\n",
    "\n",
    "    for file, size in top_n_files_with_size:\n",
    "        print(f\"{file}: {size / 1024:.0f} KB\")\n",
    "    return top_n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_files(dataset_dir, n=25, file_type=\"opus\"):\n",
    "    seed=42\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    opus_files = list(dataset_dir.rglob(f'*.{file_type}'))\n",
    "    random.Random(seed).shuffle(opus_files)\n",
    "    top_n_files = opus_files[:n]\n",
    "    top_n_files_with_size = [(str(file), file.stat().st_size) for file in top_n_files]\n",
    "\n",
    "    for file, size in top_n_files_with_size:\n",
    "        print(f\"{file}: {size / 1024:.0f} KB\")\n",
    "    return top_n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(audio, normalize=True):\n",
    "    start = time.time()\n",
    "\n",
    "    if isinstance(audio, str):\n",
    "        audio = whisperx.load_audio(audio)\n",
    "\n",
    "    num_samples = audio.shape[0]  # Get the number of samples from the shape\n",
    "    audio_length = round(num_samples / SAMPLE_RATE, 3)\n",
    "\n",
    "    result = model.transcribe(audio, batch_size=batch_size, print_progress=False, language=\"tr\")\n",
    "    transcription_time = round(time.time() - start, 2)\n",
    "    prediction = \"\"\n",
    "    for result in result[\"segments\"]:\n",
    "        prediction += result[\"text\"] + \" \"\n",
    "\n",
    "    return prediction.strip(), transcription_time, audio_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(str1: str, str2: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein distance between two strings.\n",
    "    \n",
    "    Args:\n",
    "        str1: First string\n",
    "        str2: Second string\n",
    "        \n",
    "    Returns:\n",
    "        int: The minimum number of single-character edits needed to change str1 into str2\n",
    "    \"\"\"\n",
    "    # Create a matrix of size (len(str1) + 1) x (len(str2) + 1)\n",
    "    matrix = [[0 for _ in range(len(str2) + 1)] for _ in range(len(str1) + 1)]\n",
    "    \n",
    "    # Initialize first row and column\n",
    "    for i in range(len(str1) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(str2) + 1):\n",
    "        matrix[0][j] = j\n",
    "    \n",
    "    # Fill in the rest of the matrix\n",
    "    for i in range(1, len(str1) + 1):\n",
    "        for j in range(1, len(str2) + 1):\n",
    "            if str1[i-1] == str2[j-1]:\n",
    "                matrix[i][j] = matrix[i-1][j-1]\n",
    "            else:\n",
    "                matrix[i][j] = min(\n",
    "                    matrix[i-1][j] + 1,    # deletion\n",
    "                    matrix[i][j-1] + 1,    # insertion\n",
    "                    matrix[i-1][j-1] + 1   # substitution\n",
    "                )\n",
    "    \n",
    "    return matrix[len(str1)][len(str2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_levenshtein_distance(str1: str, str2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the normalized Levenshtein distance between two strings.\n",
    "    Returns a value between 0.0 (identical) and 1.0 (completely different).\n",
    "    \n",
    "    Args:\n",
    "        str1: First string\n",
    "        str2: Second string\n",
    "        \n",
    "    Returns:\n",
    "        float: Normalized distance between 0.0 (identical) and 1.0 (completely different)\n",
    "    \"\"\"\n",
    "    # Get the raw Levenshtein distance\n",
    "    distance = levenshtein_distance(str1, str2)\n",
    "    \n",
    "    # Normalize by the length of the longer string\n",
    "    max_length = max(len(str1), len(str2))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if max_length == 0:\n",
    "        return 0.0 if len(str1) == len(str2) else 1.0\n",
    "        \n",
    "    return round(distance / max_length, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a pre-trained sentence embedding model fine-tuned on semantic similarity tasks\n",
    "# st_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')  # handles hatted chars\n",
    "# st_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "# st_model = SentenceTransformer(\"emrecan/bert-base-turkish-cased-mean-nli-stsb-tr\")  # iyi * \n",
    "st_model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")  # iyi ama hatted da kalıyor\n",
    "# st_model = SentenceTransformer(\"oguuzhansahin/bi-encoder-mnrl-dbmdz-bert-base-turkish-cased-margin_3.0-msmarco-tr-10k\")  # , device='cpu'\n",
    "\n",
    "# st_model = SentenceTransformer(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "# st_model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
    "\n",
    "def sentence_similarity(sent1, sent2):\n",
    "    # Compute the embeddings for both sentences\n",
    "    embedding1 = st_model.encode(sent1, convert_to_tensor=True)\n",
    "    embedding2 = st_model.encode(sent2, convert_to_tensor=True)\n",
    "    \n",
    "    # Calculate the cosine similarity between the two embeddings\n",
    "    cosine_sim = util.cos_sim(embedding1, embedding2)\n",
    "    return cosine_sim.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from ytk.normalizer import fill_dates\n",
    "\n",
    "SYNT_LABELS = False\n",
    "n = 9999  # Number of samples to evaluate\n",
    "# from huggingface_hub import notebook_login, login\n",
    "\n",
    "# login(token=\"TOKEN\")\n",
    "# Load the Huggingface dataset\n",
    "\n",
    "ds = \"ysdede/yeni-split-0\"\n",
    "# ds = \"ysdede/yeni-split-lq-noisy\"\n",
    "# ds = \"ysdede/ds_test\"\n",
    "# ds = \"ysdede/rad-vits-1\"\n",
    "# ds = \"erenfazlioglu/turkishvoicedataset\"\n",
    "# ds = \"ysdede/commonvoice_17_tr_fixed\"\n",
    "\n",
    "split = \"test\"\n",
    "dataset = load_dataset(ds, split=split, streaming=False, trust_remote_code=True)\n",
    "\n",
    "\n",
    "total_wer = 0\n",
    "avg_wer = 0\n",
    "processed_files = 0\n",
    "label_pairs = []\n",
    "total_dist = 0\n",
    "avg_dist = 0\n",
    "total_sim = 0\n",
    "avg_dist = 0\n",
    "\n",
    "total_audio_duration = 0\n",
    "total_transcription_time = 0\n",
    "avg_speed = 0\n",
    "\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= n:\n",
    "        break\n",
    "    try:\n",
    "        audio_array = example[\"audio\"][\"array\"].astype(np.float32)\n",
    "        sampling_rate = example[\"audio\"][\"sampling_rate\"]\n",
    "        reference = example[\"transcription\"]\n",
    "\n",
    "        if \"/aa/yyyy\" in reference:\n",
    "            reference = fill_dates(reference)\n",
    "\n",
    "        prediction, transcription_time, audio_length = transcript(audio_array)\n",
    "\n",
    "        if \"No active speech found in audio\" in prediction:\n",
    "            continue  # Skip this example\n",
    "\n",
    "        rf, pre = reference, prediction\n",
    "\n",
    "        prediction = normalize_text(prediction)\n",
    "        reference = normalize_text(reference)\n",
    "\n",
    "        wer = wer_metric.compute(references=[reference], predictions=[prediction])\n",
    "        lev_dist = normalized_levenshtein_distance(reference, prediction)\n",
    "        similarity = sentence_similarity(replace_hatted_characters(rf), replace_hatted_characters(pre))\n",
    "\n",
    "        total_wer += wer\n",
    "        processed_files += 1\n",
    "        avg_wer = total_wer / processed_files\n",
    "        total_dist += lev_dist\n",
    "        avg_dist = total_dist / processed_files\n",
    "        total_sim += similarity\n",
    "        avg_sim = total_sim / processed_files\n",
    "\n",
    "        total_audio_duration += audio_length\n",
    "        total_transcription_time += transcription_time\n",
    "        avg_speed = round(total_audio_duration / total_transcription_time, 2)\n",
    "\n",
    "        label_pairs.append((f\"{wer * 100:0.02f}\", lev_dist, rf, pre))\n",
    "\n",
    "        print(rf)\n",
    "        print(pre)\n",
    "        print(f\"{processed_files}/{len(dataset)} Avg WER: {avg_wer * 100:0.02f}%, WER: {wer * 100:0.02f}%, Avg Dist: {avg_dist:0.03f}, Distance: {lev_dist}, Sim: {similarity:0.03f}, AvgSim: {avg_sim:0.03f}, Dur: {audio_length} sec, time: {transcription_time}, Speed: {audio_length/transcription_time:0.02f}x, AvgSpeed: {avg_speed}x\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example: {e}\")\n",
    "\n",
    "\n",
    "with open(\"labels-base-new.tsv\", \"w\", encoding=\"utf-8\") as lf:\n",
    "    for wer, lev_dist, r, p in label_pairs:\n",
    "        lf.write(f\"{wer}\\t{lev_dist}\\t{r}\\t{p}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
