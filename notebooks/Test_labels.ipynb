{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "turkish_upper_chars = {\"ı\": \"I\", \"i\": \"İ\", \"ş\": \"Ş\", \"ğ\": \"Ğ\", \"ü\": \"Ü\", \"ö\": \"Ö\", \"ç\": \"Ç\"}\n",
    "\n",
    "turkish_hatted_chars = {\n",
    "    \"â\": \"a\",\n",
    "    \"Â\": \"A\",\n",
    "    \"î\": \"i\",\n",
    "    \"Î\": \"I\",\n",
    "    \"û\": \"u\",\n",
    "    \"Û\": \"U\",\n",
    "    \"ô\": \"o\",  # Bazı metinlerde karşılaşılabiliyor, standartta yer almamakla birlikte eklenmiştir.\n",
    "    \"Ô\": \"O\"\n",
    "}\n",
    "turkish_lower_chars = {v: k for k, v in turkish_upper_chars.items()}\n",
    "\n",
    "def replace_hatted_characters(s):\n",
    "    for k, v in turkish_hatted_chars.items():\n",
    "        s = s.replace(k, v)\n",
    "    return s\n",
    "\n",
    "def turkish_lower(s):\n",
    "    return \"\".join(turkish_lower_chars.get(c, c.lower()) for c in s)\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply normalization to text described in Moonshine: Speech Recognition for Live Transcription and Voice Commands\n",
    "    https://arxiv.org/html/2410.15608v2\n",
    "\n",
    "    Handle Turkish specific characters, use helper functions defined earlier.\n",
    "    \"\"\"\n",
    "    text = text.replace(\" '\", \"'\").replace(\"' \", \" \").replace(\"'\", \"\")\n",
    "    text = replace_hatted_characters(text)\n",
    "    text = turkish_lower(text)\n",
    "    text = re.sub(r'[^a-zçğıöşü]', ' ', text).replace(\"  \", \" \")\n",
    "    return text.strip()\n",
    "\n",
    "print(normalize_text(\"âîôû Çok iyi ve nazik biriydi. Prusya'daki ilk karşılaşmamızda onu konuşturmayı başarmıştım. Bana o yaz North Cape’de bulunduğunu ve Nijni Novgorod panayırına gitmeyi çok istediğini anlatmıştı.,;)([-*])\"))\n",
    "print(replace_hatted_characters(\"âîôû Çok iyi ve nazik biriydi. Prusya'daki ilk karşılaşmamızda onu konuşturmayı başarmıştım. Bana o yaz North Cape’de bulunduğunu ve Nijni Novgorod panayırına gitmeyi çok istediğini anlatmıştı.,;)([-*])\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "\n",
    "# import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "SAMPLE_RATE = 16000  # Sample rate in Hz\n",
    "NUM_SAMPLES_TO_TRIM = 0  # 4 * SAMPLE_RATE  # Number of samples in 4 seconds\n",
    "SYNT_LABELS = False\n",
    "device = \"cuda\"\n",
    "batch_size = 1  # reduce if low on GPU mem\n",
    "# compute_type = \"int8\"  # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "compute_type = \"float32\"\n",
    "\n",
    "asr_options = {\n",
    "    # \"temperatures\": 0.0,\n",
    "    \"beam_size\": 5,\n",
    "    \"condition_on_previous_text\": False,\n",
    "    # \"initial_prompt\": \"\"\n",
    "    \"hotwords\": None,\n",
    "    \"multilingual\": False,\n",
    "}\n",
    "\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-large-v3-turbo\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   # 15.54      0.067\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   # 19.8   0.066              / 27\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   # 15.82       0.058              / 45\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-small-turkish-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)    # 11.9   0.04    / 18\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-tiny-turkish-0\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)   #   22.37     0.076\n",
    "model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-base-turkish-1.1\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)\n",
    "\n",
    "# model = whisperx.load_model(\"Systran/faster-whisper-tiny\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)                        # 50     0.170\n",
    "# model = whisperx.load_model(\"N:/models/faster/Systran/faster-whisper-base\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  #\n",
    "# model = whisperx.load_model(\"N:/models/faster/Systran/faster-whisper-small\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  #\n",
    "\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-large-v3-turbo-med-tr-30k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # Çok iyi. İlk finetune, frozen, drop active, bütün parametreler vardı. Bu ctranslatre2 tokenizer vs json dosyaların ıhatalı oluşturduğu için kötü sonuç veriyormuş meğer.\n",
    "# model = whisperx.load_model(r\"N:\\models\\faster\\ysdede\\whisper-large-v3-turbo-med-tr-2-40k\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # iyi, encoder frozen olmalı. İlki yarım kalınca ve inference ı hatalı yapınca buna geçmiştim. Kısaltmaları tam öğrenememiş. Yukarıdaki daha iyi.\n",
    "# model = whisperx.load_model(\"N:/models/faster/ysdede/whisper-khanacademy-large-v3-turbo-tr\", device, compute_type=compute_type, download_root=\"n:\\\\whisperx_models\", language=\"tr\", asr_options=asr_options)  # Başarılı, bazı terimler ve kısaltmaları bilmiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_files(dataset_dir, n=25, file_type=\"opus\"):\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    opus_files = list(dataset_dir.rglob(f'*.{file_type}'))\n",
    "    print(len(opus_files))\n",
    "    sorted_opus_files = sorted(opus_files, key=lambda x: x.stat().st_size, reverse=True)\n",
    "    top_n_files = sorted_opus_files[:n]\n",
    "    top_n_files_with_size = [(str(file), file.stat().st_size) for file in top_n_files]\n",
    "\n",
    "    for file, size in top_n_files_with_size:\n",
    "        print(f\"{file}: {size / 1024:.0f} KB\")\n",
    "    return top_n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_files(dataset_dir, n=25, file_type=\"opus\"):\n",
    "    seed=42\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    opus_files = list(dataset_dir.rglob(f'*.{file_type}'))\n",
    "    random.Random(seed).shuffle(opus_files)\n",
    "    top_n_files = opus_files[:n]\n",
    "    top_n_files_with_size = [(str(file), file.stat().st_size) for file in top_n_files]\n",
    "\n",
    "    for file, size in top_n_files_with_size:\n",
    "        print(f\"{file}: {size / 1024:.0f} KB\")\n",
    "    return top_n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(audio_path, normalize=True):\n",
    "    start = time.time()\n",
    "    audio = whisperx.load_audio(audio_path)\n",
    "\n",
    "    num_samples = audio.shape[0]  # Get the number of samples from the shape\n",
    "    audio_length = round(num_samples / SAMPLE_RATE, 3)\n",
    "\n",
    "    result = model.transcribe(audio, batch_size=batch_size, print_progress=False, language=\"tr\")\n",
    "    transcription_time = round(time.time() - start, 2)\n",
    "    prediction = \"\"\n",
    "    for result in result[\"segments\"]:\n",
    "        prediction += result[\"text\"] + \" \"\n",
    "\n",
    "    return prediction.strip(), transcription_time, audio_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(str1: str, str2: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein distance between two strings.\n",
    "    \n",
    "    Args:\n",
    "        str1: First string\n",
    "        str2: Second string\n",
    "        \n",
    "    Returns:\n",
    "        int: The minimum number of single-character edits needed to change str1 into str2\n",
    "    \"\"\"\n",
    "    # Create a matrix of size (len(str1) + 1) x (len(str2) + 1)\n",
    "    matrix = [[0 for _ in range(len(str2) + 1)] for _ in range(len(str1) + 1)]\n",
    "    \n",
    "    # Initialize first row and column\n",
    "    for i in range(len(str1) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(str2) + 1):\n",
    "        matrix[0][j] = j\n",
    "    \n",
    "    # Fill in the rest of the matrix\n",
    "    for i in range(1, len(str1) + 1):\n",
    "        for j in range(1, len(str2) + 1):\n",
    "            if str1[i-1] == str2[j-1]:\n",
    "                matrix[i][j] = matrix[i-1][j-1]\n",
    "            else:\n",
    "                matrix[i][j] = min(\n",
    "                    matrix[i-1][j] + 1,    # deletion\n",
    "                    matrix[i][j-1] + 1,    # insertion\n",
    "                    matrix[i-1][j-1] + 1   # substitution\n",
    "                )\n",
    "    \n",
    "    return matrix[len(str1)][len(str2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_levenshtein_distance(str1: str, str2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the normalized Levenshtein distance between two strings.\n",
    "    Returns a value between 0.0 (identical) and 1.0 (completely different).\n",
    "    \n",
    "    Args:\n",
    "        str1: First string\n",
    "        str2: Second string\n",
    "        \n",
    "    Returns:\n",
    "        float: Normalized distance between 0.0 (identical) and 1.0 (completely different)\n",
    "    \"\"\"\n",
    "    # Get the raw Levenshtein distance\n",
    "    distance = levenshtein_distance(str1, str2)\n",
    "    \n",
    "    # Normalize by the length of the longer string\n",
    "    max_length = max(len(str1), len(str2))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if max_length == 0:\n",
    "        return 0.0 if len(str1) == len(str2) else 1.0\n",
    "        \n",
    "    return round(distance / max_length, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = r\"N:\\dataset_v3\\khanacademy-tr\\Other\\Sosyoloji___Khan_Academy\\Kulturel_Gecikme_ve_Kultur_oku_Sosyoloji_Toplum_ve_Kultur-[DpEl50Dpw7Y]\\chunk_0.mp3\"\n",
    "label = \"\"\"\"Kültürel Gecikme\" ya da \"Kültürel Boşluk\" terimi; kültürün, teknolojik gelişmeleri yakalamasının vakit almasını ve bunun, toplumsal sorunlara yol açmasını tanımlar.\"\"\"\n",
    "label = normalize_text(label)\n",
    "prediction, transcription_time, audio_length = transcript(audio_file, normalize=False)\n",
    "prediction = normalize_text(prediction)\n",
    "speed = round(audio_length / transcription_time, 2)\n",
    "print(prediction, \"\\n\", transcription_time, audio_length, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distance = levenshtein_distance(label, prediction)\n",
    "print(label)\n",
    "print(prediction)\n",
    "print(distance)\n",
    "normalized_distance = normalized_levenshtein_distance(label, prediction)\n",
    "print(normalized_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ytk.normalizer import fill_dates\n",
    "# from ytk.utils import turkish_capitalize\n",
    "from webvtt import read as read_vtt\n",
    "\n",
    "SYNT_LABELS = False\n",
    "n = 9999\n",
    "\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\YENI_SPLIT_LQ_NOISY\"\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\YENI_SPLIT\"\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\commonvoice_17_tr\\commonvoice_17_tr_fixed\\test\"\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\tr-med-audio\"\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\\YENI_SPLITTEN ARTAN\"\n",
    "# INPUT_DIR = r\"N:\\dataset_v3\"\n",
    "INPUT_DIR = \"N:\\dataset_v4\\MediaSpeech_TR\"\n",
    "\n",
    "# file_list = get_random_files(INPUT_DIR, n, file_type=\"mp3\")\n",
    "file_list = get_random_files(INPUT_DIR, n, file_type=\"wav\")\n",
    "# file_list = get_largest_files(INPUT_DIR, n, file_type=\"mp3\")\n",
    "print(len(file_list))\n",
    "\n",
    "total_wer = 0\n",
    "avg_wer = 0\n",
    "processed_files = 0\n",
    "label_pairs = []\n",
    "total_dist = 0\n",
    "avg_dist = 0\n",
    "\n",
    "def get_text_from_file(file_path):\n",
    "    \"\"\"Extract text from either VTT or TXT file.\"\"\"\n",
    "    try:\n",
    "        # Check file extension\n",
    "        if file_path.suffix.lower() == '.vtt':\n",
    "            captions = read_vtt(str(file_path))\n",
    "            transcription = ' '.join(caption.text.replace('\\n', ' ') for caption in captions).strip()\n",
    "        else:  # Assume txt file\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                transcription = f.read().replace('\\n', ' ')\n",
    "        \n",
    "        return transcription.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "for audio_path in file_list:\n",
    "    try:\n",
    "        # Try VTT first, then TXT\n",
    "        vtt_file = audio_path.with_suffix('.vtt')\n",
    "        txt_file = audio_path.with_suffix('.txt')\n",
    "        \n",
    "        if vtt_file.exists():\n",
    "            reference = get_text_from_file(vtt_file)\n",
    "            transcript_file = vtt_file\n",
    "        elif txt_file.exists():\n",
    "            reference = get_text_from_file(txt_file)\n",
    "            transcript_file = txt_file\n",
    "        else:\n",
    "            print(f\"No transcript file found for {audio_path}\")\n",
    "            continue\n",
    "            \n",
    "        if not reference or len(reference) < 5:\n",
    "            continue\n",
    "\n",
    "\n",
    "        prediction, transcription_time, audio_length = transcript(audio_path)\n",
    "        # prediction = prediction.replace(\" x \", \"x\")\n",
    "\n",
    "        if \"No active speech found in audio\" in prediction:\n",
    "            continue\n",
    "\n",
    "        rf, pre = reference, prediction\n",
    "\n",
    "        prediction = normalize_text(prediction)\n",
    "        reference = normalize_text(reference)\n",
    "\n",
    "        wer = wer_metric.compute(references=[reference], predictions=[prediction])\n",
    "        lev_dist = normalized_levenshtein_distance(reference, prediction)\n",
    "        \n",
    "        total_wer += wer\n",
    "        processed_files += 1\n",
    "        avg_wer = total_wer / processed_files\n",
    "        total_dist += lev_dist\n",
    "        avg_dist = total_dist / processed_files\n",
    "\n",
    "        \n",
    "\n",
    "        label_pairs.append((f\"{wer * 100:0.02f}\", lev_dist, rf, pre))\n",
    "\n",
    "        print(rf)\n",
    "        print(pre)\n",
    "        print(f\"{processed_files}/{len(file_list)} Avg WER: {avg_wer * 100:0.02f}%, WER: {wer * 100:0.02f}%, Avg Dist: {avg_dist:0.03f}, Distance: {lev_dist}, {audio_path} - Duration: {audio_length} sec, time: {transcription_time}, Speed: {transcription_time / audio_length:0.02f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "\n",
    "with open(\"labels-base-new.tsv\", \"w\", encoding=\"utf-8\") as lf:\n",
    "    for wer, lev_dist, r, p in label_pairs:\n",
    "        lf.write(f\"{wer}\\t{lev_dist}\\t{r}\\t{p}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webvtt-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
