{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import webvtt\n",
    "from datasets import Dataset, Audio, Value, Features, DatasetDict\n",
    "import os\n",
    "\n",
    "# Replace magic command with os.chdir for .py file\n",
    "%cd \"N:/dataset_v3\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_metadata_vtt(vtt_path):\n",
    "    \"\"\"Extract text from WebVTT file, combining all captions into one transcription.\"\"\"\n",
    "    try:\n",
    "        captions = webvtt.read(str(vtt_path))\n",
    "        # Combine all caption texts into one string, removing any newlines\n",
    "        transcription = ' '.join(caption.text.replace('\\n', ' ') for caption in captions)\n",
    "        return {\n",
    "            'transcription': transcription.strip()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading VTT file {vtt_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_metadata_json(json_path):\n",
    "    \"\"\"Extract text from JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as json_file:\n",
    "            data = json.load(json_file)\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"Error decoding JSON file: {json_path}\")\n",
    "        return None\n",
    "\n",
    "    text = data.get('text', '')\n",
    "    text_norm = data.get('text_normalized', '')\n",
    "    transcription = text or text_norm\n",
    "\n",
    "    if not transcription:\n",
    "        logging.warning(f\"No transcription found in JSON file: {json_path}\")\n",
    "        return None\n",
    "\n",
    "    return {'transcription': transcription.strip()}\n",
    "\n",
    "def scan_for_files(directory, audio_ext='.mp3', metadata_ext='.json'):\n",
    "    \"\"\"\n",
    "    Scan directory for metadata and audio file pairs.\n",
    "\n",
    "    Args:\n",
    "        directory (str or Path): Directory to scan\n",
    "        audio_ext (str): Audio file extension (default: '.mp3')\n",
    "        metadata_ext (str): Metadata file extension (default: '.json')\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    logging.info(f\"Scanning for {metadata_ext} files in {directory}...\")\n",
    "    data = []\n",
    "\n",
    "    # Get metadata handler based on extension\n",
    "    metadata_handlers = {\n",
    "        '.vtt': get_metadata_vtt,\n",
    "        '.json': get_metadata_json\n",
    "    }\n",
    "\n",
    "    if metadata_ext not in metadata_handlers:\n",
    "        raise ValueError(f\"Unsupported metadata extension: {metadata_ext}. Supported types: {list(metadata_handlers.keys())}\")\n",
    "\n",
    "    metadata_handler = metadata_handlers[metadata_ext]\n",
    "\n",
    "    try:\n",
    "        # Use os.walk instead of rglob to better handle special characters\n",
    "        for root, _, files in os.walk(str(directory)):\n",
    "            for file in files:\n",
    "                if file.endswith(metadata_ext):\n",
    "                    metadata_path = Path(os.path.join(root, file))\n",
    "                    audio_path = metadata_path.with_suffix(audio_ext)\n",
    "\n",
    "                    if not audio_path.exists():\n",
    "                        logging.warning(f\"No matching audio file found for: {metadata_path}\")\n",
    "                        continue\n",
    "\n",
    "                    # Get metadata\n",
    "                    metadata = metadata_handler(metadata_path)\n",
    "                    if not metadata:\n",
    "                        continue\n",
    "\n",
    "                    if len(metadata['transcription']) < 5:\n",
    "                        continue\n",
    "\n",
    "                    metadata['audio'] = {'path': str(audio_path)}\n",
    "                    data.append(metadata)\n",
    "\n",
    "        logging.info(f\"Found {len(data)} valid file pairs\")\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scanning directory: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def create_dataset(data_dir, audio_ext='.mp3', metadata_ext='.json'):\n",
    "    \"\"\"\n",
    "    Create dataset from directory containing metadata and audio files.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str or Path): Directory containing the data\n",
    "        audio_ext (str): Audio file extension to look for (default: '.mp3')\n",
    "        metadata_ext (str): Metadata file extension to look for (default: '.json')\n",
    "    \"\"\"\n",
    "    data = scan_for_files(data_dir, audio_ext, metadata_ext)\n",
    "\n",
    "    features = Features({\n",
    "        \"audio\": Audio(sampling_rate=16_000),\n",
    "        \"transcription\": Value(\"string\")\n",
    "    })\n",
    "\n",
    "    dataset = Dataset.from_list(data, features=features)\n",
    "    # Split the dataset into train and test\n",
    "    train_test_split = dataset.train_test_split(test_size=0.06, seed=42)\n",
    "    test_valid_split = train_test_split['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "    ds = DatasetDict({\n",
    "        'train': train_test_split['train'],\n",
    "        'test': test_valid_split['test'],\n",
    "        'validation': test_valid_split['train']\n",
    "    })\n",
    "    return ds\n",
    "\n",
    "# Example usage\n",
    "train_test_dataset = create_dataset(\n",
    "    \"N:/dataset_v3/YENI_SPLIT\",\n",
    "    audio_ext='.mp3',  # or '.opus'\n",
    "    metadata_ext='.vtt'  # or '.vtt'\n",
    ")\n",
    "\n",
    "# # Save the dataset with both splits to disk\n",
    "# train_test_dataset.save_to_disk(str(Path('ysdede/yeni-split-0').resolve()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset with both splits to disk\n",
    "train_test_dataset.save_to_disk(str(Path('ysdede/yeni-split-0').resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the dataset with both splits to the Hub\n",
    "train_test_dataset.push_to_hub('ysdede/yeni-split-0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
